# ðŸ‡§ðŸ‡· Lakehouse: Monitor EconÃ´mico do Brasil (End-to-End)

Este projeto implementa um pipeline completo de Engenharia de Dados (**ELT**), utilizando uma arquitetura **Data Lakehouse** baseada em Containers. 

O objetivo Ã© ingerir dados oficiais do **Banco Central do Brasil (BCB)**, processar sÃ©ries histÃ³ricas de CÃ¢mbio e Indicadores MacroeconÃ´micos (IPCA, Selic) e disponibilizar um dashboard analÃ­tico para tomada de decisÃ£o.

## ðŸ›ï¸ Arquitetura do Projeto

O projeto segue a **Medallion Architecture** (Bronze, Silver, Gold):

1.  **IngestÃ£o (Bronze):** O **Apache Airflow** consulta a API de Dados Abertos do BCB (SGS), baixa sÃ©ries histÃ³ricas longas (DÃ³lar, Euro, Selic, IPCA) e salva os arquivos JSON brutos no **MinIO** (Data Lake).
2.  **TransformaÃ§Ã£o (Silver):** O **DuckDB** lÃª os JSONs complexos, utiliza `UNNEST` para explodir as listas aninhadas, aplica tipagem forte (Casting) e salva o histÃ³rico particionado em **Parquet**.
3.  **ConsolidaÃ§Ã£o (Gold):** O **DuckDB** unifica os arquivos histÃ³ricos em uma tabela analÃ­tica otimizada (`economia_unificada.parquet`).
4.  **VisualizaÃ§Ã£o:** O **Streamlit** consome a camada Gold para gerar grÃ¡ficos de tendÃªncia (InflaÃ§Ã£o vs Juros) e KPIs de CÃ¢mbio.

## ðŸ› ï¸ Tech Stack

* **OrquestraÃ§Ã£o:** Apache Airflow 2.10
* **Fonte de Dados:** API Banco Central do Brasil (SGS)
* **Storage (Data Lake):** MinIO (S3 Compatible)
* **Processamento:** DuckDB (In-memory SQL OLAP)
* **VisualizaÃ§Ã£o:** Streamlit + Plotly
* **Infraestrutura:** Docker & Docker Compose

## ðŸš€ Como Rodar

### PrÃ©-requisitos
* Docker e Docker Compose instalados.

### Passo a Passo

1.  Clone o repositÃ³rio:
    ```bash
    git clone [https://github.com/Matheuslagos/tcc-lakehouse.git](https://github.com/Matheuslagos/tcc-lakehouse.git)
    cd tcc-lakehouse
    ```

2.  Suba o ambiente (Build & Run):
    ```bash
    docker compose up --build -d
    ```

3.  Acesse os serviÃ§os:

| ServiÃ§o | URL | Credenciais (User/Pass) |
|---|---|---|
| **Airflow** | `http://localhost:8080` | `admin` / `admin` |
| **MinIO** | `http://localhost:9001` | `admin` / `password123` |
| **Dashboard** | `http://localhost:8501` | *(Acesso Livre)* |

4.  No Airflow, ative a DAG **`elt_economia_bcb`**.
    * *Nota:* Ela estÃ¡ configurada para rodar diariamente (dias Ãºteis), mas vocÃª pode executar manualmente (Trigger) para carga inicial.

## ðŸ“‚ Estrutura de Pastas

```text
â”œâ”€â”€ dags/                  
â”‚   â””â”€â”€ elt_valores_economicos.py  # Pipeline ELT (ExtraÃ§Ã£o BCB -> Silver -> Gold)
â”œâ”€â”€ dashboard.py           # AplicaÃ§Ã£o Streamlit (KPIs e GrÃ¡ficos Macro)
â”œâ”€â”€ docker-compose.yaml    # DefiniÃ§Ã£o da Infraestrutura
â”œâ”€â”€ Dockerfile             # Imagem Customizada do Airflow
â”œâ”€â”€ Dockerfile.streamlit   # Imagem Customizada do Dashboard
â””â”€â”€ requirements.txt       # DependÃªncias Python